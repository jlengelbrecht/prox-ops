---
# MCP Server Catalog Sync Workflow
# Automatically generates registry catalog entries from MCPServer CRD definitions
#
# Triggers when MCPServer files are added/modified in PRs or merged to main
# Validates the MCPServer, checks security, builds containers, and generates catalog entries
#
# IMPORTANT: After merge, it takes ~2-3 minutes for new MCP servers to appear in the catalog.
# The ToolHive registry syncs from GitHub on a 2-minute interval, plus Flux reconciliation time.
name: "MCP Catalog Sync"

on:
  push:
    branches: ["main"]
    paths:
      # Trigger on merge to main when MCPServer files change
      - "kubernetes/apps/mcp/toolhive-gateway/app/mcpserver-*.yaml"
  pull_request:
    branches: ["main"]
    paths:
      # Only trigger on MCPServer CRD additions/modifications
      # registry.json is auto-generated by this workflow, not manually edited
      - "kubernetes/apps/mcp/toolhive-gateway/app/mcpserver-*.yaml"
  workflow_dispatch:
    inputs:
      force_regenerate:
        description: "Force regenerate all catalog entries"
        required: false
        default: "false"
        type: boolean

concurrency:
  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}
  cancel-in-progress: true

# Default to read-only permissions; jobs that need write access override explicitly
permissions:
  contents: read
  pull-requests: read

env:
  MCPSERVER_PATH: "kubernetes/apps/mcp/toolhive-gateway/app"
  REGISTRY_PATH: "kubernetes/apps/mcp/registry-data/registry.json"
  # Tool versions managed by mise (.mise.toml) - yq, thv installed via setup-mcp-tools action

jobs:
  # =============================================================================
  # Job 1: Pre-flight - Detect MCPServer changes
  # =============================================================================
  preflight:
    name: Detect MCP Changes
    runs-on: gha-runner-scale-set
    outputs:
      mcpservers_changed: ${{ steps.changed.outputs.mcpservers_changed }}
      mcpserver_files: ${{ steps.changed.outputs.mcpserver_files }}
      registry_changed: ${{ steps.changed.outputs.registry_changed }}
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Detect Changed Files
        id: changed
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.event.inputs.force_regenerate }}" = "true" ]; then
            echo "Force regenerate requested - processing all MCPServer files"
            MCPSERVER_FILES=$(find "${{ env.MCPSERVER_PATH }}" -name "mcpserver-*.yaml" -type f | sort)
            echo "mcpservers_changed=true" >> "$GITHUB_OUTPUT"
            echo "registry_changed=false" >> "$GITHUB_OUTPUT"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            # Get changed files in PR using PR-specific refs
            # Use --diff-filter=d to exclude deleted files for validation (we can't validate files that don't exist)
            CHANGED=$(git diff --name-only --diff-filter=d ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }})
            MCPSERVER_FILES=$(echo "$CHANGED" | grep -E "^${{ env.MCPSERVER_PATH }}/mcpserver-.*\.yaml$" || true)
            REGISTRY_CHANGED=$(echo "$CHANGED" | grep -E "^${{ env.REGISTRY_PATH }}$" || true)

            # Also check for deleted MCPServer files - we still need to regenerate the catalog
            DELETED_MCPSERVERS=$(git diff --name-only --diff-filter=D ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }} | grep -E "^${{ env.MCPSERVER_PATH }}/mcpserver-.*\.yaml$" || true)

            if [ -n "$MCPSERVER_FILES" ] || [ -n "$DELETED_MCPSERVERS" ]; then
              echo "mcpservers_changed=true" >> "$GITHUB_OUTPUT"
              if [ -n "$DELETED_MCPSERVERS" ]; then
                echo "MCPServer files deleted (catalog will be regenerated):"
                echo "$DELETED_MCPSERVERS"
              fi
            else
              echo "mcpservers_changed=false" >> "$GITHUB_OUTPUT"
            fi

            if [ -n "$REGISTRY_CHANGED" ]; then
              echo "registry_changed=true" >> "$GITHUB_OUTPUT"
            else
              echo "registry_changed=false" >> "$GITHUB_OUTPUT"
            fi
          elif [ "${{ github.event_name }}" = "push" ]; then
            # Push to main - process all MCPServer files (Flux reconciliation)
            # The push path trigger already filters to mcpserver-*.yaml changes
            CHANGED=$(git diff --name-only --diff-filter=d HEAD~1..HEAD 2>/dev/null || echo "")
            MCPSERVER_FILES=$(echo "$CHANGED" | grep -E "^${{ env.MCPSERVER_PATH }}/mcpserver-.*\.yaml$" || true)

            if [ -n "$MCPSERVER_FILES" ]; then
              echo "mcpservers_changed=true" >> "$GITHUB_OUTPUT"
            else
              echo "mcpservers_changed=false" >> "$GITHUB_OUTPUT"
            fi
            echo "registry_changed=false" >> "$GITHUB_OUTPUT"
          else
            # workflow_dispatch without force_regenerate - no changes to process
            echo "workflow_dispatch without force_regenerate - skipping"
            MCPSERVER_FILES=""
            echo "mcpservers_changed=false" >> "$GITHUB_OUTPUT"
            echo "registry_changed=false" >> "$GITHUB_OUTPUT"
          fi

          # Store files as JSON array for matrix
          if [ -n "$MCPSERVER_FILES" ]; then
            FILES_JSON=$(echo "$MCPSERVER_FILES" | jq -R -s -c 'split("\n") | map(select(length > 0))')
            echo "mcpserver_files=$FILES_JSON" >> "$GITHUB_OUTPUT"
            echo "MCPServer files to process:"
            echo "$MCPSERVER_FILES"
          else
            echo "mcpserver_files=[]" >> "$GITHUB_OUTPUT"
            echo "No MCPServer files changed"
          fi

  # =============================================================================
  # Job 2: Validate MCPServer definitions
  # =============================================================================
  validate:
    name: Validate MCPServer
    needs: preflight
    # Only run when there are actual files to validate (not just deletions)
    if: needs.preflight.outputs.mcpservers_changed == 'true' && needs.preflight.outputs.mcpserver_files != '[]'
    runs-on: gha-runner-scale-set
    strategy:
      matrix:
        file: ${{ fromJson(needs.preflight.outputs.mcpserver_files) }}
      fail-fast: false
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup MCP Tools
        uses: ./.github/actions/setup-mcp-tools

      - name: Validate YAML Syntax
        run: |
          echo "Validating YAML syntax for: ${{ matrix.file }}"
          yq eval '.' "${{ matrix.file }}" > /dev/null
          echo "YAML syntax is valid"

      - name: Validate Required Fields
        id: validate-fields
        run: |
          FILE="${{ matrix.file }}"
          echo "Validating required fields in: $FILE"

          ERRORS=""

          # Required spec fields
          IMAGE=$(yq eval '.spec.image // ""' "$FILE")
          TRANSPORT=$(yq eval '.spec.transport // ""' "$FILE")
          NAME=$(yq eval '.metadata.name // ""' "$FILE")

          if [ -z "$IMAGE" ]; then
            ERRORS="${ERRORS}Missing required field: spec.image\n"
          fi

          if [ -z "$TRANSPORT" ]; then
            ERRORS="${ERRORS}Missing required field: spec.transport\n"
          fi

          if [ -z "$NAME" ]; then
            ERRORS="${ERRORS}Missing required field: metadata.name\n"
          fi

          # Catalog annotation requirements (for registry generation)
          CATALOG_TITLE=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-title"] // ""' "$FILE")
          CATALOG_TOOLS=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-tools"] // ""' "$FILE")
          REPO_URL=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/repository-url"] // ""' "$FILE")

          # Warn if catalog annotations missing (not fatal, but needed for catalog)
          WARNINGS=""
          if [ -z "$CATALOG_TITLE" ]; then
            WARNINGS="${WARNINGS}Missing annotation: toolhive.stacklok.dev/catalog-title\n"
          fi
          if [ -z "$CATALOG_TOOLS" ]; then
            WARNINGS="${WARNINGS}Missing annotation: toolhive.stacklok.dev/catalog-tools\n"
          fi
          if [ -z "$REPO_URL" ]; then
            WARNINGS="${WARNINGS}Missing annotation: toolhive.stacklok.dev/repository-url\n"
          fi

          if [ -n "$ERRORS" ]; then
            echo "::error::Validation failed for $FILE"
            printf '%b' "$ERRORS"
            exit 1
          fi

          if [ -n "$WARNINGS" ]; then
            echo "::warning::$FILE is missing catalog annotations - catalog entry may be incomplete"
            printf '%b' "$WARNINGS"
          fi

          echo "Validation passed for $FILE"
          echo "name=$NAME" >> "$GITHUB_OUTPUT"
          echo "image=$IMAGE" >> "$GITHUB_OUTPUT"

      - name: Check for Hardcoded Secrets
        run: |
          FILE="${{ matrix.file }}"
          echo "Checking for hardcoded secrets in: $FILE"

          # Patterns that suggest hardcoded secrets
          PATTERNS=(
            "password:"
            "api_key:"
            "apiKey:"
            "secret:"
            "token:"
            "sk-"
            "Bearer "
            "ghp_"
            "gho_"
            "glpat-"
            "PRIVATE_KEY"
            "private.key"
            "AWS_SECRET"
          )

          FOUND=""
          for pattern in "${PATTERNS[@]}"; do
            # Check env values (not names or references to secrets)
            if yq eval '.spec.env[].value' "$FILE" 2>/dev/null | grep -qi "$pattern"; then
              FOUND="${FOUND}Potential secret pattern found: $pattern\n"
            fi
          done

          if [ -n "$FOUND" ]; then
            echo "::error::Potential hardcoded secrets detected in $FILE"
            printf '%b' "$FOUND"
            echo "Use spec.secrets with ExternalSecrets instead of hardcoding values"
            exit 1
          fi

          echo "No hardcoded secrets detected"

      - name: Validate Reloader Policy for ExternalSecrets
        run: |
          FILE="${{ matrix.file }}"
          MCP_DIR="${{ env.MCPSERVER_PATH }}"
          echo "Validating Reloader policy for ExternalSecrets in: $FILE"

          # Get unique secret names referenced by this MCPServer
          SECRET_NAMES=$(yq eval '.spec.secrets[].name // ""' "$FILE" 2>/dev/null | sort -u | grep -v '^$' || true)

          if [ -z "$SECRET_NAMES" ]; then
            echo "No secrets referenced - skipping reloader validation"
            exit 0
          fi

          echo "Referenced secrets: $(echo $SECRET_NAMES | tr '\n' ' ')"

          # Get the reloader annotation from podTemplateSpec
          RELOADER_ANNOTATION=$(yq eval '.spec.podTemplateSpec.metadata.annotations["secret.reloader.stakater.com/reload"] // ""' "$FILE")

          ERRORS=0

          for SECRET_NAME in $SECRET_NAMES; do
            echo ""
            echo "Checking secret: $SECRET_NAME"

            # Search for an ExternalSecret that creates this secret
            # Look in the same directory and parent MCP directory
            EXTERNAL_SECRET_FILE=""
            for es_file in "$MCP_DIR"/../*/app/externalsecret*.yaml "$MCP_DIR"/externalsecret*.yaml; do
              [ -f "$es_file" ] || continue

              # Check if this ExternalSecret creates our secret (spec.target.name or metadata.name)
              # Use eval-all to handle multi-document YAML files
              TARGET_NAME=$(yq eval-all 'select(.kind == "ExternalSecret") | (.spec.target.name // .metadata.name)' "$es_file" 2>/dev/null | head -n1 || true)

              if [ "$TARGET_NAME" = "$SECRET_NAME" ]; then
                EXTERNAL_SECRET_FILE="$es_file"
                break
              fi
            done

            if [ -n "$EXTERNAL_SECRET_FILE" ]; then
              echo "  → Secret is backed by ExternalSecret: $EXTERNAL_SECRET_FILE"
              echo "  → This is a 1Password-managed secret - Reloader annotation REQUIRED"

              # Verify reloader annotation includes this secret
              if [ -z "$RELOADER_ANNOTATION" ]; then
                echo "::error::MCPServer '$FILE' uses ExternalSecret '$SECRET_NAME' but has NO Reloader annotation"
                echo ""
                echo "Add to spec.podTemplateSpec.metadata.annotations:"
                echo "  secret.reloader.stakater.com/reload: \"$SECRET_NAME\""
                ERRORS=$((ERRORS + 1))
              elif ! echo ",$RELOADER_ANNOTATION," | grep -qF ",$SECRET_NAME,"; then
                # Use comma-delimited matching to avoid false positives on substring matches
                # e.g., "api" should not match "my-api-keys"
                echo "::error::Reloader annotation does not include secret '$SECRET_NAME'"
                echo "  Current: $RELOADER_ANNOTATION"
                echo "  Expected to include: $SECRET_NAME"
                ERRORS=$((ERRORS + 1))
              else
                echo "  ✓ Reloader annotation correctly configured"
              fi
            else
              echo "  → Secret is not an ExternalSecret (inline or manual) - no reloader required"
            fi
          done

          if [ "$ERRORS" -gt 0 ]; then
            echo ""
            echo "::error::$ERRORS Reloader policy violation(s) found"
            echo ""
            echo "MCPServers using ExternalSecrets (1Password) MUST have Reloader annotations"
            echo "to ensure pods automatically restart when secrets are updated in 1Password."
            exit 1
          fi

          echo ""
          echo "Reloader policy validation passed"

      - name: Validate SecurityContext Configuration
        run: |
          FILE="${{ matrix.file }}"
          echo "Validating SecurityContext in: $FILE"

          ERRORS=0
          WARNINGS=0

          # NOTE: yq's // operator treats 'false' as falsy, so we use 'type' checks instead
          # to properly detect boolean false values vs missing fields

          # Check for runAsNonRoot in podTemplateSpec
          RUN_AS_NON_ROOT=$(yq eval '.spec.podTemplateSpec.spec.securityContext.runAsNonRoot' "$FILE")
          if [ "$RUN_AS_NON_ROOT" = "true" ]; then
            echo "✓ runAsNonRoot: true"
          elif [ "$RUN_AS_NON_ROOT" = "null" ]; then
            echo "::warning::Missing runAsNonRoot: true in podTemplateSpec.spec.securityContext"
            WARNINGS=$((WARNINGS + 1))
          else
            echo "::warning::runAsNonRoot should be true, found: $RUN_AS_NON_ROOT"
            WARNINGS=$((WARNINGS + 1))
          fi

          # Check for seccompProfile
          SECCOMP=$(yq eval '.spec.podTemplateSpec.spec.securityContext.seccompProfile.type' "$FILE")
          if [ "$SECCOMP" = "null" ] || [ -z "$SECCOMP" ]; then
            echo "::warning::Missing seccompProfile in podTemplateSpec.spec.securityContext"
            WARNINGS=$((WARNINGS + 1))
          else
            echo "✓ seccompProfile: $SECCOMP"
          fi

          # Check container security context - allowPrivilegeEscalation must be false
          CONTAINER_ALLOW_PRIV=$(yq eval '.spec.podTemplateSpec.spec.containers[0].securityContext.allowPrivilegeEscalation' "$FILE")
          if [ "$CONTAINER_ALLOW_PRIV" = "false" ]; then
            echo "✓ allowPrivilegeEscalation: false"
          elif [ "$CONTAINER_ALLOW_PRIV" = "null" ]; then
            echo "::error::Container must have allowPrivilegeEscalation: false (field missing)"
            ERRORS=$((ERRORS + 1))
          else
            echo "::error::Container must have allowPrivilegeEscalation: false (found: $CONTAINER_ALLOW_PRIV)"
            ERRORS=$((ERRORS + 1))
          fi

          # Check for capability drops
          CAPS_DROP=$(yq eval '.spec.podTemplateSpec.spec.containers[0].securityContext.capabilities.drop[0]' "$FILE")
          if [ "$CAPS_DROP" = "ALL" ]; then
            echo "✓ capabilities.drop: ALL"
          elif [ "$CAPS_DROP" = "null" ]; then
            echo "::warning::Container should drop ALL capabilities (field missing)"
            WARNINGS=$((WARNINGS + 1))
          else
            echo "::warning::Container should drop ALL capabilities (found: $CAPS_DROP)"
            WARNINGS=$((WARNINGS + 1))
          fi

          # Check readOnlyRootFilesystem
          READ_ONLY=$(yq eval '.spec.podTemplateSpec.spec.containers[0].securityContext.readOnlyRootFilesystem' "$FILE")
          if [ "$READ_ONLY" = "true" ]; then
            echo "✓ readOnlyRootFilesystem: true"
          elif [ "$READ_ONLY" = "null" ]; then
            echo "::warning::Container should have readOnlyRootFilesystem: true (field missing)"
            WARNINGS=$((WARNINGS + 1))
          else
            echo "::warning::Container should have readOnlyRootFilesystem: true (found: $READ_ONLY)"
            WARNINGS=$((WARNINGS + 1))
          fi

          # Check automountServiceAccountToken
          AUTOMOUNT=$(yq eval '.spec.podTemplateSpec.spec.automountServiceAccountToken' "$FILE")
          if [ "$AUTOMOUNT" = "false" ]; then
            echo "✓ automountServiceAccountToken: false"
          elif [ "$AUTOMOUNT" = "null" ]; then
            echo "::warning::Pod should have automountServiceAccountToken: false (field missing)"
            WARNINGS=$((WARNINGS + 1))
          else
            echo "::warning::Pod should have automountServiceAccountToken: false (found: $AUTOMOUNT)"
            WARNINGS=$((WARNINGS + 1))
          fi

          if [ "$ERRORS" -gt 0 ]; then
            echo ""
            echo "::error::SecurityContext validation failed with $ERRORS error(s) and $WARNINGS warning(s)"
            exit 1
          fi

          if [ "$WARNINGS" -gt 0 ]; then
            echo ""
            echo "::warning::SecurityContext validation passed with $WARNINGS warning(s)"
          else
            echo ""
            echo "SecurityContext validation passed"
          fi

      - name: Validate NetworkPolicy Coverage
        run: |
          FILE="${{ matrix.file }}"
          MCP_DIR="${{ env.MCPSERVER_PATH }}"
          ERRORS=0
          echo "Validating NetworkPolicy coverage for: $FILE"

          # Extract MCPServer name for policy correlation
          MCP_NAME=$(yq eval '.metadata.name' "$FILE")
          echo "MCPServer name: $MCP_NAME"

          # Check if this MCPServer needs network access (has permissionProfile: network)
          PERMISSION_PROFILE=$(yq eval '.spec.permissionProfile.name // ""' "$FILE")
          NEEDS_NETWORK=false

          if [ "$PERMISSION_PROFILE" = "network" ]; then
            NEEDS_NETWORK=true
            echo "MCP server has network permission profile - checking for egress policy"
          fi

          # Search for CiliumNetworkPolicy that covers this MCPServer
          # ToolHive uses labels: toolhive: "true", toolhive-name: <name>
          POLICY_FILE="$MCP_DIR/networkpolicy-mcpservers.yaml"

          if [ -f "$POLICY_FILE" ]; then
            # Check if there's a specific policy for this MCPServer (for private network access)
            SPECIFIC_POLICY=$(yq eval-all "select(.kind == \"CiliumNetworkPolicy\" and .spec.endpointSelector.matchLabels.\"toolhive-name\" == \"$MCP_NAME\")" "$POLICY_FILE" 2>/dev/null || true)

            if [ -n "$SPECIFIC_POLICY" ] && [ "$SPECIFIC_POLICY" != "null" ]; then
              echo "✓ Found specific CiliumNetworkPolicy for $MCP_NAME"

              # Verify it has egress rules if network is needed
              if [ "$NEEDS_NETWORK" = "true" ]; then
                EGRESS_RULES=$(echo "$SPECIFIC_POLICY" | yq eval '.spec.egress | length' -)
                if [ "$EGRESS_RULES" -eq 0 ]; then
                  echo "::error::NetworkPolicy exists but has no egress rules (required for network access)"
                  ERRORS=$((ERRORS + 1))
                else
                  echo "✓ NetworkPolicy has $EGRESS_RULES egress rule(s)"
                fi
              fi
            else
              # Check if covered by generic toolhive policy
              GENERIC_POLICY=$(yq eval-all "select(.kind == \"CiliumNetworkPolicy\" and .spec.endpointSelector.matchLabels.toolhive == \"true\" and .spec.endpointSelector.matchLabels.\"toolhive-name\" == null)" "$POLICY_FILE" 2>/dev/null || true)

              if [ -n "$GENERIC_POLICY" ] && [ "$GENERIC_POLICY" != "null" ]; then
                echo "✓ MCPServer covered by generic ToolHive network policy"

                # Check if MCP needs private network access (TrueNAS, UniFi, etc.)
                # These require specific policies with toCIDRSet for private ranges
                DESCRIPTION=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/registry-description"] // ""' "$FILE")

                if echo "$DESCRIPTION" | grep -qiE "(truenas|unifi|private|homelab|internal)"; then
                  if [ "$NEEDS_NETWORK" = "true" ]; then
                    echo "::error::$MCP_NAME needs private network access but lacks specific NetworkPolicy"
                    echo "A dedicated policy with toCIDRSet for private IP ranges is required"
                    ERRORS=$((ERRORS + 1))
                  else
                    echo "::warning::$MCP_NAME may need private network access but lacks specific NetworkPolicy"
                    echo "Consider adding a dedicated policy with toCIDRSet for private IP ranges"
                  fi
                fi
              else
                if [ "$NEEDS_NETWORK" = "true" ]; then
                  echo "::error::No NetworkPolicy found covering $MCP_NAME (required for network access)"
                  echo "ToolHive MCPServers with network permission profile must have CiliumNetworkPolicy"
                  ERRORS=$((ERRORS + 1))
                else
                  echo "::warning::No NetworkPolicy found covering $MCP_NAME"
                  echo "ToolHive MCPServers should have CiliumNetworkPolicy for security"
                fi
              fi
            fi
          else
            if [ "$NEEDS_NETWORK" = "true" ]; then
              echo "::error::NetworkPolicy file not found: $POLICY_FILE (required for network access)"
              ERRORS=$((ERRORS + 1))
            else
              echo "::warning::NetworkPolicy file not found: $POLICY_FILE"
            fi
          fi

          echo ""
          if [ "$ERRORS" -gt 0 ]; then
            echo "::error::NetworkPolicy validation failed with $ERRORS error(s)"
            exit 1
          fi
          echo "NetworkPolicy validation completed"

  # =============================================================================
  # Job 3: Classify MCPServers into deployment paths
  # =============================================================================
  # PATH A: Source-built (has mcp-source comment) - CI/CD builds container
  # PATH B: Pre-built (no mcp-source) - Use maintainer's container directly
  # =============================================================================
  classify:
    name: Classify Deployment Paths
    needs: [preflight, validate]
    if: |
      always() &&
      needs.preflight.outputs.mcpservers_changed == 'true' &&
      needs.preflight.outputs.mcpserver_files != '[]' &&
      (needs.validate.result == 'success' || needs.validate.result == 'skipped')
    runs-on: gha-runner-scale-set
    outputs:
      build_matrix: ${{ steps.classify.outputs.build_matrix }}
      prebuilt_matrix: ${{ steps.classify.outputs.prebuilt_matrix }}
      has_builds: ${{ steps.classify.outputs.has_builds }}
      has_prebuilt: ${{ steps.classify.outputs.has_prebuilt }}
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup MCP Tools
        uses: ./.github/actions/setup-mcp-tools

      - name: Classify MCPServers
        id: classify
        run: |
          BUILD_MATRIX="[]"      # PATH A: needs container build
          PREBUILT_MATRIX="[]"   # PATH B: pre-built, scan only

          # Process each file from preflight
          FILES='${{ needs.preflight.outputs.mcpserver_files }}'

          for file in $(echo "$FILES" | jq -r '.[]'); do
            echo "=== Classifying: $file ==="

            IMAGE=$(yq eval '.spec.image' "$file")
            MCP_SOURCE=$(grep -oP '#\s*mcp-source:\s*\K.*' "$file" || echo "")

            echo "  spec.image: $IMAGE"
            echo "  mcp-source: ${MCP_SOURCE:-<none>}"

            if [ -n "$MCP_SOURCE" ]; then
              # PATH A: Has mcp-source → source-built container
              echo "  Path: A (source-built)"

              # Extract version from mcp-source
              SOURCE_VERSION=$(echo "$MCP_SOURCE" | grep -oP '@\K[^@\s]+$' || echo "")

              # Extract version from current spec.image
              CURRENT_VERSION=$(echo "$IMAGE" | grep -oP ':\K[^:]+$' || echo "")

              echo "  Source version: $SOURCE_VERSION"
              echo "  Image version: $CURRENT_VERSION"

              # Determine protocol and package name
              PROTOCOL=""
              PACKAGE=""
              DATASOURCE=""

              # Note: sed patterns use (.+)@[^@]+$ to support scoped packages (e.g., @scope/pkg@1.0.0)
              # The .+ greedily matches, then backtracks to find the last @ before version
              if echo "$MCP_SOURCE" | grep -qE '^uvx://'; then
                PROTOCOL="uvx"
                PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^uvx://(.+)@[^@]+$|\1|')
                DATASOURCE="pypi"
              elif echo "$MCP_SOURCE" | grep -qE '^npx://'; then
                PROTOCOL="npx"
                PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^npx://(.+)@[^@]+$|\1|')
                DATASOURCE="npm"
              elif echo "$MCP_SOURCE" | grep -qE '^go://'; then
                PROTOCOL="go"
                PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^go://(.+)@[^@]+$|\1|')
                DATASOURCE="go"
              elif echo "$MCP_SOURCE" | grep -qE '^github://'; then
                PROTOCOL="github"
                PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^github://(.+)@[^@]+$|\1|')
                DATASOURCE="github-releases"
              fi

              echo "  Protocol: $PROTOCOL"
              echo "  Package: $PACKAGE"

              # Fail-fast: Validate required fields before proceeding
              if [ -z "$PROTOCOL" ] || [ -z "$PACKAGE" ]; then
                echo "::error::Failed to extract protocol/package from mcp-source: $MCP_SOURCE"
                echo "::error::Protocol='$PROTOCOL', Package='$PACKAGE'"
                exit 1
              fi
              if [ -z "$SOURCE_VERSION" ]; then
                echo "::error::Failed to extract version from mcp-source: $MCP_SOURCE"
                exit 1
              fi

              # Determine if build is needed (version mismatch)
              NEEDS_BUILD="false"
              if [ "$SOURCE_VERSION" != "$CURRENT_VERSION" ]; then
                NEEDS_BUILD="true"
                echo "  Status: VERSION MISMATCH - build needed"
              else
                echo "  Status: versions match - no build needed"
              fi

              # Use jq -c for compact (single-line) JSON output for GITHUB_OUTPUT
              BUILD_MATRIX=$(echo "$BUILD_MATRIX" | jq -c \
                --arg file "$file" \
                --arg source "$MCP_SOURCE" \
                --arg protocol "$PROTOCOL" \
                --arg package "$PACKAGE" \
                --arg datasource "$DATASOURCE" \
                --arg source_version "$SOURCE_VERSION" \
                --arg current_version "$CURRENT_VERSION" \
                --arg needs_build "$NEEDS_BUILD" \
                '. + [{
                  "file": $file,
                  "source": $source,
                  "protocol": $protocol,
                  "package": $package,
                  "datasource": $datasource,
                  "source_version": $source_version,
                  "current_version": $current_version,
                  "needs_build": ($needs_build == "true"),
                  "path": "A"
                }]')
            else
              # PATH B: No mcp-source → pre-built container
              echo "  Path: B (pre-built)"

              # Use jq -c for compact (single-line) JSON output for GITHUB_OUTPUT
              PREBUILT_MATRIX=$(echo "$PREBUILT_MATRIX" | jq -c \
                --arg file "$file" \
                --arg image "$IMAGE" \
                '. + [{
                  "file": $file,
                  "image": $image,
                  "path": "B"
                }]')
            fi

            echo ""
          done

          # Output matrices
          echo "build_matrix=$BUILD_MATRIX" >> "$GITHUB_OUTPUT"
          echo "prebuilt_matrix=$PREBUILT_MATRIX" >> "$GITHUB_OUTPUT"

          # Output flags
          BUILD_COUNT=$(echo "$BUILD_MATRIX" | jq 'length')
          PREBUILT_COUNT=$(echo "$PREBUILT_MATRIX" | jq 'length')
          NEEDS_BUILD_COUNT=$(echo "$BUILD_MATRIX" | jq '[.[] | select(.needs_build == true)] | length')

          echo "has_builds=$( [ "$NEEDS_BUILD_COUNT" -gt 0 ] && echo true || echo false )" >> "$GITHUB_OUTPUT"
          echo "has_prebuilt=$( [ "$PREBUILT_COUNT" -gt 0 ] && echo true || echo false )" >> "$GITHUB_OUTPUT"

          echo "=== Classification Summary ==="
          echo "PATH A (source-built): $BUILD_COUNT files"
          echo "  - Needs build: $NEEDS_BUILD_COUNT"
          echo "PATH B (pre-built): $PREBUILT_COUNT files"

  # =============================================================================
  # Job 4: Security scan (BLOCKING on HIGH/CRITICAL)
  # =============================================================================
  # PATH A (source-built): Scans source packages (pip-audit, npm audit, etc.)
  # PATH B (pre-built): Scans container images (Trivy)
  # =============================================================================
  image-scan:
    name: Security Scan
    needs: [preflight, validate, classify]
    if: |
      always() &&
      needs.preflight.outputs.mcpservers_changed == 'true' &&
      needs.preflight.outputs.mcpserver_files != '[]' &&
      (needs.classify.result == 'success' || needs.classify.result == 'skipped')
    runs-on: gha-runner-scale-set
    permissions:
      contents: read
      pull-requests: write   # Required: Post security scan results as PR comment
    strategy:
      matrix:
        file: ${{ fromJson(needs.preflight.outputs.mcpserver_files) }}
      fail-fast: false
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup MCP Tools
        uses: ./.github/actions/setup-mcp-tools

      - name: Determine Scan Type
        id: image
        run: |
          FILE="${{ matrix.file }}"
          echo "file=$FILE" >> "$GITHUB_OUTPUT"

          # Check classification from classify job outputs
          BUILD_MATRIX='${{ needs.classify.outputs.build_matrix }}'
          PREBUILT_MATRIX='${{ needs.classify.outputs.prebuilt_matrix }}'

          # Find this file in either matrix
          BUILD_ENTRY=$(echo "$BUILD_MATRIX" | jq --arg f "$FILE" '.[] | select(.file == $f)' 2>/dev/null || echo "")
          PREBUILT_ENTRY=$(echo "$PREBUILT_MATRIX" | jq --arg f "$FILE" '.[] | select(.file == $f)' 2>/dev/null || echo "")

          if [ -n "$BUILD_ENTRY" ] && [ "$BUILD_ENTRY" != "null" ]; then
            # PATH A: Source-built - extract info from classification
            echo "path=A" >> "$GITHUB_OUTPUT"
            PROTOCOL=$(echo "$BUILD_ENTRY" | jq -r '.protocol')
            PACKAGE=$(echo "$BUILD_ENTRY" | jq -r '.package')
            VERSION=$(echo "$BUILD_ENTRY" | jq -r '.source_version')
            SOURCE=$(echo "$BUILD_ENTRY" | jq -r '.source')

            echo "protocol=$PROTOCOL" >> "$GITHUB_OUTPUT"
            echo "package=$PACKAGE" >> "$GITHUB_OUTPUT"
            echo "version=$VERSION" >> "$GITHUB_OUTPUT"
            echo "source=$SOURCE" >> "$GITHUB_OUTPUT"

            # Set image_type based on protocol for downstream steps
            case "$PROTOCOL" in
              uvx)
                echo "image_type=pypi" >> "$GITHUB_OUTPUT"
                echo "pypi_package=${PACKAGE}==${VERSION}" >> "$GITHUB_OUTPUT"
                ;;
              npx)
                echo "image_type=npm" >> "$GITHUB_OUTPUT"
                echo "npm_package=${PACKAGE}@${VERSION}" >> "$GITHUB_OUTPUT"
                ;;
              go)
                echo "image_type=go" >> "$GITHUB_OUTPUT"
                ;;
              github)
                echo "image_type=github" >> "$GITHUB_OUTPUT"
                ;;
            esac

            echo "PATH A: Scanning source package $PACKAGE@$VERSION ($PROTOCOL)"

          elif [ -n "$PREBUILT_ENTRY" ] && [ "$PREBUILT_ENTRY" != "null" ]; then
            # PATH B: Pre-built - scan docker image
            echo "path=B" >> "$GITHUB_OUTPUT"
            echo "image_type=docker" >> "$GITHUB_OUTPUT"
            IMAGE=$(echo "$PREBUILT_ENTRY" | jq -r '.image')
            echo "image=$IMAGE" >> "$GITHUB_OUTPUT"

            echo "PATH B: Scanning pre-built image $IMAGE"

          else
            # Fallback: read from file directly
            echo "::warning::File not found in classification matrices, reading directly"
            IMAGE=$(yq eval '.spec.image' "$FILE")
            MCP_SOURCE=$(grep -oP '#\s*mcp-source:\s*\K.*' "$FILE" || echo "")

            if [ -n "$MCP_SOURCE" ]; then
              echo "path=A" >> "$GITHUB_OUTPUT"
              # Note: sed patterns use (.+)@([^@]+)$ to support scoped packages
              if echo "$MCP_SOURCE" | grep -qE '^uvx://'; then
                echo "image_type=pypi" >> "$GITHUB_OUTPUT"
                PYPI_PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^uvx://(.+)@([^@]+)$|\1==\2|')
                echo "pypi_package=$PYPI_PACKAGE" >> "$GITHUB_OUTPUT"
              elif echo "$MCP_SOURCE" | grep -qE '^npx://'; then
                echo "image_type=npm" >> "$GITHUB_OUTPUT"
                NPM_PACKAGE=$(echo "$MCP_SOURCE" | sed -E 's|^npx://(.+)$|\1|')
                echo "npm_package=$NPM_PACKAGE" >> "$GITHUB_OUTPUT"
              fi
            else
              # Fail fast: If file isn't in matrices and has no mcp-source, classification is broken
              echo "::error::Classification error: File $FILE not found in classification matrices"
              echo "::error::spec.image value: $IMAGE"
              echo "::error::This indicates a bug in the classify job - all MCPServer files should be classified"
              echo "::error::Check the 'Classify Deployment Paths' job output for issues"
              exit 1
            fi
          fi

      - name: Run Trivy Scan (Docker images)
        id: trivy
        if: steps.image.outputs.image_type == 'docker'
        uses: aquasecurity/trivy-action@b6643a29fecd7f34b3597bc6acb0a98b03d33ff8 # v0.33.1
        with:
          image-ref: ${{ steps.image.outputs.image }}
          format: "json"
          output: "trivy-results.json"
          exit-code: "1"  # BLOCKING: Fail on HIGH/CRITICAL vulnerabilities
          severity: "HIGH,CRITICAL"
          ignore-unfixed: true

      - name: Process Trivy Results
        if: steps.image.outputs.image_type == 'docker' && always()
        id: trivy-process
        run: |
          if [ -f "trivy-results.json" ]; then
            # Extract vulnerability counts
            CRITICAL=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' trivy-results.json)
            HIGH=$(jq '[.Results[]?.Vulnerabilities[]? | select(.Severity == "HIGH")] | length' trivy-results.json)

            echo "critical_count=$CRITICAL" >> "$GITHUB_OUTPUT"
            echo "high_count=$HIGH" >> "$GITHUB_OUTPUT"

            # Generate summary table
            echo "=== Vulnerability Summary ==="
            echo "Critical: $CRITICAL"
            echo "High: $HIGH"

            if [ "$CRITICAL" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
              echo ""
              echo "=== Vulnerability Details ==="
              jq -r '.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL" or .Severity == "HIGH") | "[\(.Severity)] \(.VulnerabilityID): \(.PkgName) - \(.Title // "No title")"' trivy-results.json | head -20
              echo "scan_status=failed" >> "$GITHUB_OUTPUT"
            else
              echo "scan_status=passed" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "No Trivy results file found"
            echo "scan_status=skipped" >> "$GITHUB_OUTPUT"
          fi

      - name: Setup Python (for PyPI audit)
        if: steps.image.outputs.image_type == 'pypi'
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.12"

      - name: Run pip-audit (PyPI packages)
        id: pip-audit
        if: steps.image.outputs.image_type == 'pypi'
        run: |
          PACKAGE="${{ steps.image.outputs.pypi_package }}"
          echo "Auditing PyPI package: $PACKAGE"

          # Install pip-audit
          python -m pip install pip-audit --quiet

          # Create temporary requirements file
          echo "$PACKAGE" > /tmp/requirements.txt

          # Run pip-audit with JSON output for processing
          echo "=== Vulnerability Scan Results ==="
          pip-audit -r /tmp/requirements.txt --progress-spinner=off --format=json --output=/tmp/pip-audit-results.json 2>/dev/null || true

          # Process results - handle various pip-audit output formats
          if [ -f /tmp/pip-audit-results.json ]; then
            # Debug: Show the JSON structure
            echo "=== Raw JSON Output ==="
            cat /tmp/pip-audit-results.json | head -50
            echo ""
            echo "=== JSON Structure Analysis ==="

            # pip-audit JSON format varies:
            # Standard: {"dependencies": [{"name": "pkg", "version": "1.0", "vulns": [...]}]}
            # Or array: [{"name": "pkg", "version": "1.0", "vulns": [...]}]
            # Detect format and extract vulnerabilities accordingly

            # Check if top-level has 'dependencies' key (newer format) or is direct array (older format)
            HAS_DEPS_KEY=$(jq 'has("dependencies")' /tmp/pip-audit-results.json 2>/dev/null || echo "false")
            IS_ARRAY=$(jq 'type == "array"' /tmp/pip-audit-results.json 2>/dev/null || echo "false")

            echo "Has dependencies key: $HAS_DEPS_KEY"
            echo "Is array: $IS_ARRAY"

            if [ "$HAS_DEPS_KEY" = "true" ]; then
              # Newer format: {"dependencies": [...]}
              VULN_COUNT=$(jq '[.dependencies[]? | .vulns // [] | length] | add // 0' /tmp/pip-audit-results.json 2>/dev/null || echo "0")
              VULN_DETAILS_CMD='.dependencies[]? | select((.vulns // []) | length > 0) | .name as $pkg | .version as $ver | (.vulns // [])[] | "[HIGH] \(.id // "unknown"): \($pkg) \($ver) - Fix: \(.fix_versions | join(", ") // "No fix available")"'
            elif [ "$IS_ARRAY" = "true" ]; then
              # Array format: [{"name": ..., "vulns": ...}]
              VULN_COUNT=$(jq '[.[]? | .vulns // [] | length] | add // 0' /tmp/pip-audit-results.json 2>/dev/null || echo "0")
              VULN_DETAILS_CMD='.[]? | select((.vulns // []) | length > 0) | .name as $pkg | .version as $ver | (.vulns // [])[] | "[HIGH] \(.id // "unknown"): \($pkg) \($ver) - Fix: \(.fix_versions | join(", ") // "No fix available")"'
            else
              # Unknown format - try to handle gracefully
              echo "::warning::Unknown pip-audit JSON format, attempting fallback parsing"
              VULN_COUNT=$(jq '.. | .vulns? // empty | length' /tmp/pip-audit-results.json 2>/dev/null | jq -s 'add // 0' || echo "0")
              VULN_DETAILS_CMD='.. | select(type == "object" and .vulns?) | .name as $pkg | .version as $ver | .vulns[] | "[HIGH] \(.id // "unknown"): \($pkg // "unknown") \($ver // "?") - Fix: \(.fix_versions | join(", ") // "No fix available")"'
            fi

            echo "Vulnerabilities found: $VULN_COUNT"
            echo "vuln_count=$VULN_COUNT" >> "$GITHUB_OUTPUT"

            if [ "$VULN_COUNT" -gt 0 ]; then
              echo ""
              echo "=== Vulnerability Details ==="
              jq -r "$VULN_DETAILS_CMD" /tmp/pip-audit-results.json 2>/dev/null | head -20 || echo "Could not parse vulnerability details"
              echo "scan_status=failed" >> "$GITHUB_OUTPUT"
              echo ""
              echo "::error::pip-audit found $VULN_COUNT vulnerabilities in $PACKAGE"
              echo "::notice::To resolve: Check if a newer version is available that fixes these vulnerabilities"
              exit 1  # BLOCKING: Fail on any vulnerability
            else
              echo "No vulnerabilities found"
              echo "scan_status=passed" >> "$GITHUB_OUTPUT"
            fi
          else
            # Fallback to text output if JSON failed
            echo "::warning::JSON output not generated, falling back to text"
            if ! pip-audit -r /tmp/requirements.txt --progress-spinner=off; then
              echo "scan_status=failed" >> "$GITHUB_OUTPUT"
              echo "::error::pip-audit found vulnerabilities (text fallback mode)"
              exit 1
            fi
            echo "scan_status=passed" >> "$GITHUB_OUTPUT"
          fi

          # Also check package metadata
          echo ""
          echo "=== Package Metadata ==="
          python -m pip index versions "${PACKAGE%%==*}" 2>/dev/null | head -5 || echo "Could not fetch package versions"

      - name: Setup Node.js (for npm audit)
        if: steps.image.outputs.image_type == 'npm'
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4.4.0
        with:
          node-version: "22"

      - name: Run npm audit (npm packages)
        id: npm-audit
        if: steps.image.outputs.image_type == 'npm'
        run: |
          PACKAGE="${{ steps.image.outputs.npm_package }}"
          echo "Auditing npm package: $PACKAGE"

          # Create temporary package.json with the dependency
          mkdir -p /tmp/npm-audit
          cd /tmp/npm-audit

          # Extract package name and version
          PKG_NAME=$(echo "$PACKAGE" | sed -E 's/@[^@]+$//')
          PKG_VERSION=$(echo "$PACKAGE" | grep -oE '@[^@]+$' | tr -d '@')
          [ -z "$PKG_VERSION" ] && PKG_VERSION="latest"

          # Use jq to safely construct JSON (prevents injection from special characters)
          jq -n \
            --arg name "$PKG_NAME" \
            --arg version "$PKG_VERSION" \
            '{name: "audit-check", version: "1.0.0", dependencies: {($name): $version}}' \
            > package.json

          # Install and audit
          echo "=== Installing package ==="
          npm install --ignore-scripts --package-lock-only 2>/dev/null || true

          echo ""
          echo "=== Vulnerability Scan Results ==="
          npm audit --json 2>/dev/null > /tmp/npm-audit-results.json || true

          # Process results
          if [ -f /tmp/npm-audit-results.json ]; then
            # Count HIGH and CRITICAL vulnerabilities
            CRITICAL=$(jq '[.vulnerabilities // {} | to_entries[] | select(.value.severity == "critical")] | length' /tmp/npm-audit-results.json 2>/dev/null || echo "0")
            HIGH=$(jq '[.vulnerabilities // {} | to_entries[] | select(.value.severity == "high")] | length' /tmp/npm-audit-results.json 2>/dev/null || echo "0")

            echo "Critical: $CRITICAL"
            echo "High: $HIGH"
            echo "critical_count=$CRITICAL" >> "$GITHUB_OUTPUT"
            echo "high_count=$HIGH" >> "$GITHUB_OUTPUT"

            # Display vulnerability details
            jq -r '
              if .vulnerabilities then
                .vulnerabilities | to_entries[] |
                select(.value.severity == "critical" or .value.severity == "high") |
                "[\(.value.severity | ascii_upcase)] \(.key): \(.value.via[0].title // .value.via[0])"
              else
                empty
              end
            ' /tmp/npm-audit-results.json | head -20 || true

            if [ "$CRITICAL" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
              echo "scan_status=failed" >> "$GITHUB_OUTPUT"
              echo "::error::npm audit found $CRITICAL critical and $HIGH high vulnerabilities in $PACKAGE"
              exit 1  # BLOCKING: Fail on HIGH/CRITICAL vulnerabilities
            else
              echo "No HIGH/CRITICAL vulnerabilities found"
              echo "scan_status=passed" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "Could not run npm audit"
            echo "scan_status=skipped" >> "$GITHUB_OUTPUT"
          fi

      - name: Consolidate Scan Results
        if: always()
        id: scan-summary
        run: |
          # Consolidate results from whichever scanner ran (trivy, pip-audit, or npm-audit)
          CRITICAL="${{ steps.trivy-process.outputs.critical_count }}"
          HIGH="${{ steps.trivy-process.outputs.high_count }}"
          STATUS="${{ steps.trivy-process.outputs.scan_status }}"

          # Fallback to pip-audit results
          if [ -z "$STATUS" ]; then
            STATUS="${{ steps.pip-audit.outputs.scan_status }}"
            CRITICAL="0"
            HIGH="${{ steps.pip-audit.outputs.vuln_count }}"
          fi

          # Fallback to npm-audit results
          if [ -z "$STATUS" ]; then
            STATUS="${{ steps.npm-audit.outputs.scan_status }}"
            CRITICAL="${{ steps.npm-audit.outputs.critical_count }}"
            HIGH="${{ steps.npm-audit.outputs.high_count }}"
          fi

          echo "critical_count=${CRITICAL:-0}" >> "$GITHUB_OUTPUT"
          echo "high_count=${HIGH:-0}" >> "$GITHUB_OUTPUT"
          echo "scan_status=${STATUS:-skipped}" >> "$GITHUB_OUTPUT"

          # Extract CVE details for PR comment (trivy only for now)
          if [ -f "trivy-results.json" ]; then
            CVE_LIST=$(jq -r '.Results[]?.Vulnerabilities[]? | select(.Severity == "CRITICAL" or .Severity == "HIGH") | "| \(.Severity) | [\(.VulnerabilityID)](https://nvd.nist.gov/vuln/detail/\(.VulnerabilityID)) | \(.PkgName) | \(.Title // "No description") |"' trivy-results.json 2>/dev/null | head -20)
            echo "cve_details<<EOF" >> "$GITHUB_OUTPUT"
            echo "$CVE_LIST" >> "$GITHUB_OUTPUT"
            echo "EOF" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate GitHub App Token (for PR comment)
        if: always() && github.event_name == 'pull_request'
        id: generate-token
        uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2
        with:
          app-id: ${{ secrets.BOT_APP_ID }}
          private-key: ${{ secrets.BOT_APP_PRIVATE_KEY }}

      - name: Comment Security Scan Results on PR
        if: always() && github.event_name == 'pull_request'
        uses: mshick/add-pr-comment@b8f338c590a895d50bcbfa6c5859251edc8952fc # v2.8.2
        with:
          repo-token: ${{ steps.generate-token.outputs.token }}
          message-id: "mcp-security-scan-${{ matrix.file }}"
          message-failure: |
            ## :rotating_light: MCP Security Scan Failed

            **File:** `${{ matrix.file }}`
            **Image:** `${{ steps.image.outputs.image }}`
            **Scan Type:** ${{ steps.image.outputs.image_type }}

            ### Vulnerability Summary

            | Severity | Count |
            |----------|-------|
            | Critical | ${{ steps.scan-summary.outputs.critical_count }} |
            | High | ${{ steps.scan-summary.outputs.high_count }} |

            ### CVE Details

            | Severity | CVE | Package | Description |
            |----------|-----|---------|-------------|
            ${{ steps.scan-summary.outputs.cve_details }}

            ### What to do

            These vulnerabilities are in the **upstream container image**, not in this repository's code.

            - **Option 1:** Wait for the upstream maintainer to release a patched version
            - **Option 2:** Open an issue on the upstream repository requesting a dependency update
            - **Option 3:** If the risk is acceptable, add a security exemption with justification

            > HIGH/CRITICAL vulnerabilities block PR merge. Review the Security Scan job logs for full details.
          message-success: |
            ## :white_check_mark: MCP Security Scan Passed

            **File:** `${{ matrix.file }}`
            **Image:** `${{ steps.image.outputs.image }}`
            **Scan Type:** ${{ steps.image.outputs.image_type }}

            No HIGH or CRITICAL vulnerabilities detected.

  # =============================================================================
  # Job 4: MCP Protocol Validation (optional - requires thv CLI)
  # =============================================================================
  mcp-validate:
    name: Validate MCP Protocol
    needs: [preflight, validate]
    # Only run when there are actual files to validate (not just deletions)
    if: |
      always() &&
      needs.preflight.outputs.mcpservers_changed == 'true' &&
      needs.preflight.outputs.mcpserver_files != '[]' &&
      (needs.validate.result == 'success' || needs.validate.result == 'skipped')
    runs-on: gha-runner-scale-set
    strategy:
      matrix:
        file: ${{ fromJson(needs.preflight.outputs.mcpserver_files) }}
      fail-fast: false
    continue-on-error: true  # Don't block PR - MCP servers may need external deps
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup MCP Tools
        uses: ./.github/actions/setup-mcp-tools

      - name: Extract MCP Server Config
        id: config
        run: |
          FILE="${{ matrix.file }}"
          NAME=$(yq eval '.metadata.name' "$FILE")
          IMAGE=$(yq eval '.spec.image' "$FILE")
          TRANSPORT=$(yq eval '.spec.transport' "$FILE")
          DECLARED_TOOLS=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-tools"] // ""' "$FILE")

          echo "name=$NAME" >> "$GITHUB_OUTPUT"
          echo "image=$IMAGE" >> "$GITHUB_OUTPUT"
          echo "transport=$TRANSPORT" >> "$GITHUB_OUTPUT"
          echo "declared_tools=$DECLARED_TOOLS" >> "$GITHUB_OUTPUT"

          echo "MCP Server: $NAME"
          echo "Image: $IMAGE"
          echo "Transport: $TRANSPORT"
          echo "Declared tools: $DECLARED_TOOLS"

      - name: Start MCP Server Container
        id: start-server
        run: |
          IMAGE="${{ steps.config.outputs.image }}"
          NAME="${{ steps.config.outputs.name }}"
          TRANSPORT="${{ steps.config.outputs.transport }}"

          echo "Starting MCP server container for validation..."

          # For stdio transport, we can't easily test without running thv
          # For streamable-http, we can start the container and probe it
          if [ "$TRANSPORT" = "streamable-http" ]; then
            # Start container with default port
            if ! docker run -d --name "mcp-test-$NAME" \
              -p 8080:8080 \
              -e SERVER__PORT=8080 \
              "$IMAGE" 2>&1; then
              echo "::warning::Failed to start container - may need required env vars"
              echo "started=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi

            # Wait for container to be ready with poll-based health check
            READY=false
            for i in {1..30}; do
              if ! docker ps | grep -q "mcp-test-$NAME"; then
                echo "::warning::Container exited after ${i}s"
                break
              fi
              # Check if MCP endpoint responds
              if curl -sf http://localhost:8080/mcp >/dev/null 2>&1 || \
                 curl -sf http://localhost:8080/health >/dev/null 2>&1; then
                echo "Container ready after ${i}s"
                READY=true
                break
              fi
              sleep 1
            done

            # Set output based on readiness
            if [ "$READY" = "true" ]; then
              echo "started=true" >> "$GITHUB_OUTPUT"
              echo "url=http://localhost:8080/mcp" >> "$GITHUB_OUTPUT"
            else
              echo "::warning::Container not ready after 30s - likely missing required dependencies"
              docker logs "mcp-test-$NAME" 2>&1 | tail -20 || true
              echo "started=false" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "::notice::stdio transport - using thv for validation"
            echo "started=skip" >> "$GITHUB_OUTPUT"
          fi

      - name: Validate MCP Tools (HTTP transport)
        if: steps.start-server.outputs.started == 'true'
        run: |
          URL="${{ steps.start-server.outputs.url }}"
          DECLARED="${{ steps.config.outputs.declared_tools }}"

          echo "Querying MCP server at $URL..."

          # Use thv to list tools
          TOOLS_JSON=$(thv mcp list tools --server "$URL" --format json 2>/dev/null) || {
            echo "::warning::Could not query MCP tools - server may not be ready"
            exit 0
          }

          echo "Tools returned by server:"
          echo "$TOOLS_JSON" | jq -r '.[].name' 2>/dev/null || echo "$TOOLS_JSON"

          # Compare with declared tools if provided
          if [ -n "$DECLARED" ]; then
            echo ""
            echo "Comparing with declared tools in annotations..."
            ACTUAL_TOOLS=$(echo "$TOOLS_JSON" | jq -r '.[].name' | sort | tr '\n' ',' | sed 's/,$//')
            DECLARED_SORTED=$(echo "$DECLARED" | tr ',' '\n' | sort | tr '\n' ',' | sed 's/,$//')

            if [ "$ACTUAL_TOOLS" != "$DECLARED_SORTED" ]; then
              echo "::warning::Tool mismatch detected"
              echo "Declared: $DECLARED_SORTED"
              echo "Actual: $ACTUAL_TOOLS"
            else
              echo "Tools match declared annotations"
            fi
          fi

      - name: Validate MCP Tools (stdio transport)
        if: steps.start-server.outputs.started == 'skip'
        run: |
          NAME="${{ steps.config.outputs.name }}"
          IMAGE="${{ steps.config.outputs.image }}"

          # stdio transport validation requires thv to create Kubernetes workloads
          # (StatefulSets, MCPGroups CRD) which needs cluster RBAC not available in CI.
          # Validate what we can: image reference format and declared tools annotation.
          echo "stdio transport: skipping live validation (requires cluster RBAC)"
          echo "  Server: $NAME"
          echo "  Image: $IMAGE"

          DECLARED="${{ steps.config.outputs.declared_tools }}"
          if [ -n "$DECLARED" ]; then
            echo "  Declared tools: $DECLARED"
            echo "::notice::stdio server '$NAME' has declared tools annotation - will be validated at deploy time"
          else
            echo "::warning::stdio server '$NAME' has no declared tools annotation - consider adding catalog-tools metadata"
          fi

      - name: Cleanup
        if: always()
        run: |
          NAME="${{ steps.config.outputs.name }}"
          docker rm -f "mcp-test-$NAME" 2>/dev/null || true

  # =============================================================================
  # Job 5: Build Containers (PATH A only - source-built MCPServers)
  # =============================================================================
  # Uses thv build to create containers from uvx://, npx://, go://, github:// sources
  # Pushes to GHCR and updates MCPServer manifests with new image reference
  # =============================================================================
  build-container:
    name: Build Container
    needs: [preflight, classify, image-scan]
    # Only run if there are PATH A files that need building
    if: |
      always() &&
      needs.classify.result == 'success' &&
      needs.classify.outputs.has_builds == 'true' &&
      (needs.image-scan.result == 'success' || needs.image-scan.result == 'skipped')
    # Use GitHub-hosted runner for Docker support (self-hosted runners lack Docker daemon)
    runs-on: ubuntu-latest
    permissions:
      contents: write    # Required: Commit manifest updates to PR
      packages: write    # Required: Push to GHCR
    strategy:
      matrix:
        include: ${{ fromJson(needs.classify.outputs.build_matrix) }}
      fail-fast: false
      # Serialize to prevent race conditions when committing to same branch
      max-parallel: 1
    # Only process entries that need building
    steps:
      - name: Check if Build Needed
        id: check
        run: |
          NEEDS_BUILD="${{ matrix.needs_build }}"
          if [ "$NEEDS_BUILD" != "true" ]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
            echo "Skipping ${{ matrix.file }} - versions already match"
          else
            echo "skip=false" >> "$GITHUB_OUTPUT"
            echo "Building container for ${{ matrix.file }}"
          fi

      - name: Checkout
        if: steps.check.outputs.skip != 'true'
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          # Use head_ref for PRs, ref_name for workflow_dispatch/push
          ref: ${{ github.head_ref || github.ref_name }}
          fetch-depth: 0

      - name: Setup MCP Tools
        if: steps.check.outputs.skip != 'true'
        uses: ./.github/actions/setup-mcp-tools

      - name: Login to GHCR
        if: steps.check.outputs.skip != 'true'
        uses: docker/login-action@74a5d142397b4f367a81961eba4e8cd7edddf772 # v3.4.0
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build Container
        id: build
        if: steps.check.outputs.skip != 'true'
        run: |
          SOURCE="${{ matrix.source }}"
          PACKAGE="${{ matrix.package }}"
          VERSION="${{ matrix.source_version }}"
          PROTOCOL="${{ matrix.protocol }}"

          # Normalize package name for Docker image naming
          # Scoped npm packages like @scope/pkg become scope-pkg
          # Remove leading @ and replace / with -
          IMAGE_PACKAGE=$(echo "$PACKAGE" | sed -E 's|^@||; s|/|-|g')

          # Sanitize version for Docker tag compatibility
          # Docker tags can only contain: a-z, A-Z, 0-9, underscore, period, hyphen
          # Replace '+' (semver build metadata) with '_', strip any other invalid chars
          SAFE_VERSION=$(echo "$VERSION" | sed -E 's/\+/_/g; s/[^A-Za-z0-9._-]//g')

          # Generate image name following convention: ghcr.io/jlengelbrecht/mcp/<package>:<version>
          IMAGE_NAME="ghcr.io/jlengelbrecht/mcp/${IMAGE_PACKAGE}:${SAFE_VERSION}"

          echo "=== Building Container ==="
          echo "Source: $SOURCE"
          echo "Package: $PACKAGE"
          echo "Normalized for Docker: $IMAGE_PACKAGE"
          echo "Version: $VERSION (sanitized: $SAFE_VERSION)"
          echo "Protocol: $PROTOCOL"
          echo "Target Image: $IMAGE_NAME"
          echo ""

          # Verify Docker is available
          echo "Checking Docker availability..."
          if ! docker info > /dev/null 2>&1; then
            echo "::error::Docker is not available or not running"
            echo "Docker info output:"
            docker info 2>&1 || true
            exit 1
          fi
          echo "Docker is available"

          # Build using thv CLI with debug output
          echo "Running: thv build $SOURCE --tag $IMAGE_NAME"
          if ! thv build --debug "$SOURCE" --tag "$IMAGE_NAME" 2>&1; then
            echo "::error::thv build failed"
            echo "Trying dry-run to see generated Dockerfile..."
            thv build --dry-run "$SOURCE" 2>&1 || true
            exit 1
          fi

          # Also tag as latest
          docker tag "$IMAGE_NAME" "ghcr.io/jlengelbrecht/mcp/${IMAGE_PACKAGE}:latest"

          echo "image_name=$IMAGE_NAME" >> "$GITHUB_OUTPUT"
          echo "image_package=$IMAGE_PACKAGE" >> "$GITHUB_OUTPUT"
          echo "package=$PACKAGE" >> "$GITHUB_OUTPUT"
          echo "version=$VERSION" >> "$GITHUB_OUTPUT"

      - name: Push to GHCR
        if: steps.check.outputs.skip != 'true'
        run: |
          IMAGE_NAME="${{ steps.build.outputs.image_name }}"
          IMAGE_PACKAGE="${{ steps.build.outputs.image_package }}"

          echo "Pushing $IMAGE_NAME to GHCR..."
          docker push "$IMAGE_NAME"
          docker push "ghcr.io/jlengelbrecht/mcp/${IMAGE_PACKAGE}:latest"

          echo "Successfully pushed:"
          echo "  - $IMAGE_NAME"
          echo "  - ghcr.io/jlengelbrecht/mcp/${IMAGE_PACKAGE}:latest"

      - name: Update MCPServer Manifest
        if: steps.check.outputs.skip != 'true'
        run: |
          FILE="${{ matrix.file }}"
          IMAGE_NAME="${{ steps.build.outputs.image_name }}"

          echo "Updating spec.image in $FILE to $IMAGE_NAME"

          # Update spec.image to the new GHCR image
          yq eval -i ".spec.image = \"$IMAGE_NAME\"" "$FILE"

          # Show the change
          echo "Updated manifest:"
          grep -A1 "spec:" "$FILE" | head -10

      - name: Generate GitHub App Token
        if: steps.check.outputs.skip != 'true'
        id: generate-token
        uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2
        with:
          app-id: ${{ secrets.BOT_APP_ID }}
          private-key: ${{ secrets.BOT_APP_PRIVATE_KEY }}

      - name: Commit Manifest Update
        if: steps.check.outputs.skip != 'true'
        env:
          GH_TOKEN: ${{ steps.generate-token.outputs.token }}
          # Use head_ref for PRs, ref_name for workflow_dispatch/push
          HEAD_REF: ${{ github.head_ref || github.ref_name }}
        run: |
          FILE="${{ matrix.file }}"
          PACKAGE="${{ steps.build.outputs.package }}"
          VERSION="${{ steps.build.outputs.version }}"
          IMAGE_NAME="${{ steps.build.outputs.image_name }}"

          # Guard: Ensure HEAD_REF is set (should always be with fallback)
          if [ -z "$HEAD_REF" ]; then
            echo "::error::HEAD_REF is empty - cannot determine branch for push"
            exit 1
          fi

          # Validate HEAD_REF to prevent command injection from untrusted branch names
          if ! echo "$HEAD_REF" | grep -qE '^[A-Za-z0-9._/-]+$'; then
            echo "::error::Invalid head_ref value - potential injection attempt"
            exit 1
          fi

          # Configure git for GitHub App bot
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Use GitHub App token for push authentication
          git remote set-url origin "https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git"

          # Stash local changes (from yq manifest update) before pulling
          # Track whether stash was created (might be empty if no changes)
          STASH_BEFORE=$(git stash list | wc -l)
          git stash --include-untracked
          STASH_AFTER=$(git stash list | wc -l)
          STASH_CREATED=0
          if [ "$STASH_AFTER" -gt "$STASH_BEFORE" ]; then
            STASH_CREATED=1
            echo "Stashed local changes"
          else
            echo "No local changes to stash"
          fi

          # Pull latest changes (in case other matrix jobs committed)
          # Fail fast on rebase conflicts instead of swallowing errors
          if ! git pull --rebase origin "$HEAD_REF"; then
            echo "::error::Rebase failed - likely concurrent change conflict on $HEAD_REF"
            echo "::error::This shouldn't happen with max-parallel: 1, check workflow configuration"
            git rebase --abort 2>/dev/null || true
            # Only pop stash if we created one
            if [ "$STASH_CREATED" = "1" ]; then
              git stash pop 2>/dev/null || true
            fi
            exit 1
          fi

          # Restore stashed changes - only if we created a stash
          if [ "$STASH_CREATED" = "1" ]; then
            if ! git stash pop; then
              echo "::error::Failed to restore stashed changes - likely conflict with pulled changes"
              echo "::error::This indicates a race condition between matrix jobs"
              # Cleanup: abort any in-progress operations and reset
              git rebase --abort 2>/dev/null || true
              git merge --abort 2>/dev/null || true
              git reset --hard HEAD
              git stash drop 2>/dev/null || true
              exit 1
            fi
          fi

          # Check if there are changes to commit
          if git diff --quiet "$FILE"; then
            echo "No changes to commit for $FILE"
          else
            git add "$FILE"
            git commit -m "chore(mcp): build container for ${PACKAGE}@${VERSION}

          Built from mcp-source using thv build.
          Image: ${IMAGE_NAME}"
            git push
            echo "Committed and pushed manifest update"
          fi

  # =============================================================================
  # Job 6: Generate Registry Catalog Entry
  # =============================================================================
  generate-catalog:
    name: Generate Catalog Entry
    needs: [preflight, validate, image-scan, build-container]
    # Run when MCPServers changed AND validate passed or was skipped (deletions only)
    # Security scan failures should NOT block catalog generation - the status check job
    # gates merge independently. Catalog entries are needed for registry sync on push to main.
    # build-container may be skipped or failed (due to scan failure) - that's OK for catalog
    if: |
      always() &&
      needs.preflight.outputs.mcpservers_changed == 'true' &&
      (needs.validate.result == 'success' || needs.validate.result == 'skipped') &&
      !cancelled()
    runs-on: gha-runner-scale-set
    permissions:
      contents: write       # Required: Auto-commit registry.json changes to PR
      pull-requests: write  # Required: Add status comment to PR
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          # Use head_ref for PRs, ref_name for workflow_dispatch/push
          ref: ${{ github.head_ref || github.ref_name }}
          fetch-depth: 0

      - name: Setup MCP Tools
        uses: ./.github/actions/setup-mcp-tools

      - name: Generate Registry Entries
        id: generate
        run: |
          # Process all MCPServer files and generate registry.json
          # Using MCP Registry API upstream format for clean names and full metadata
          # Name format: owner/repo from repository URL (e.g., getzep/graphiti)
          REGISTRY_FILE="${{ env.REGISTRY_PATH }}"
          MCPSERVER_DIR="${{ env.MCPSERVER_PATH }}"
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          # Start building servers array (upstream format)
          SERVERS="[]"
          SERVER_COUNT=0

          for mcpfile in "$MCPSERVER_DIR"/mcpserver-*.yaml; do
            [ -f "$mcpfile" ] || continue

            echo "Processing: $mcpfile"

            # Extract metadata from MCPServer
            K8S_NAME=$(yq eval '.metadata.name' "$mcpfile")
            TITLE=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-title"] // ""' "$mcpfile")
            DESCRIPTION=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/registry-description"] // "No description available"' "$mcpfile")
            TOOLS_CSV=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-tools"] // ""' "$mcpfile")
            TAGS_CSV=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/catalog-tags"] // "mcp"' "$mcpfile")
            REPO_URL=$(yq eval '.metadata.annotations["toolhive.stacklok.dev/repository-url"] // ""' "$mcpfile")

            # Extract image and version from tag
            # Supports both Docker images (image:tag) and uvx images (uvx://package@version)
            IMAGE=$(yq eval '.spec.image' "$mcpfile")
            if echo "$IMAGE" | grep -qE '^uvx://'; then
              # uvx:// format: uvx://truenas-mcp-server@3.0.2 -> 3.0.2
              VERSION=$(echo "$IMAGE" | sed -E 's/.*@([^@]+)$/\1/')
            else
              # Docker format: image:tag -> tag
              VERSION=$(echo "$IMAGE" | sed -E 's/.*:([^:]+)$/\1/')
            fi
            [ "$VERSION" = "$IMAGE" ] && VERSION="latest"

            # Extract proxyMode for remote transport type
            PROXY_MODE=$(yq eval '.spec.proxyMode // "streamable-http"' "$mcpfile")

            # Build server name from repository URL (owner/repo format)
            # e.g., https://github.com/getzep/graphiti -> getzep/graphiti
            # For multiple instances of same repo, use owner/k8s-name for uniqueness
            if [ -n "$REPO_URL" ]; then
              REPO_OWNER=$(echo "$REPO_URL" | sed -E 's|https?://github\.com/([^/]+)/.*|\1|')
              REPO_NAME=$(echo "$REPO_URL" | sed -E 's|https?://github\.com/([^/]+/[^/]+).*|\1|')
              # Check if this repo name will be duplicated (multiple MCPServers from same repo)
              # Use grep -F for fixed-string matching to avoid regex metacharacter issues in URLs
              DUPE_COUNT=$(grep -lF "$REPO_URL" "$MCPSERVER_DIR"/mcpserver-*.yaml 2>/dev/null | wc -l)
              if [ "$DUPE_COUNT" -gt 1 ]; then
                # Multiple instances from same repo - use owner/k8s-name for uniqueness
                SERVER_NAME="${REPO_OWNER}/${K8S_NAME}"
              else
                SERVER_NAME="$REPO_NAME"
              fi
              REPO_SOURCE="github"
            else
              SERVER_NAME="homelab/${K8S_NAME}"
              REPO_SOURCE="unknown"
            fi

            # If title not set, generate from server name
            if [ -z "$TITLE" ]; then
              TITLE=$(echo "$K8S_NAME" | sed 's/-/ /g' | awk '{for(i=1;i<=NF;i++) $i=toupper(substr($i,1,1)) substr($i,2)}1')
            fi

            # Convert CSV to JSON arrays
            TOOLS_JSON=$(echo "$TOOLS_CSV" | tr ',' '\n' | jq -R -s -c 'split("\n") | map(select(length > 0) | gsub("^\\s+|\\s+$"; ""))')
            TAGS_JSON=$(echo "$TAGS_CSV" | tr ',' '\n' | jq -R -s -c 'split("\n") | map(select(length > 0) | gsub("^\\s+|\\s+$"; ""))')

            # Build the endpoint URL (uses k8s name for routing)
            ENDPOINT_URL="https://mcp.homelab0.org/servers/${K8S_NAME}/mcp"

            # Create server entry in upstream format
            SERVER_ENTRY=$(jq -n \
              --arg name "$SERVER_NAME" \
              --arg title "$TITLE" \
              --arg description "$DESCRIPTION" \
              --arg version "$VERSION" \
              --arg repo_url "$REPO_URL" \
              --arg repo_source "$REPO_SOURCE" \
              --arg remote_type "$PROXY_MODE" \
              --arg endpoint_url "$ENDPOINT_URL" \
              --argjson tools "$TOOLS_JSON" \
              --argjson tags "$TAGS_JSON" \
              '{
                "name": $name,
                "title": $title,
                "description": $description,
                "version": $version,
                "repository": {
                  "url": $repo_url,
                  "source": $repo_source
                },
                "remotes": [
                  {
                    "type": $remote_type,
                    "url": $endpoint_url
                  }
                ],
                "tools": $tools,
                "tags": $tags
              }')

            # Add to servers array
            SERVERS=$(echo "$SERVERS" | jq --argjson entry "$SERVER_ENTRY" '. + [$entry]')
            SERVER_COUNT=$((SERVER_COUNT + 1))

            echo "  Added: $SERVER_NAME (version: $VERSION)"
          done

          # Build final registry.json in upstream format
          REGISTRY=$(jq -n \
            --arg schema "https://raw.githubusercontent.com/stacklok/toolhive-registry-server/main/internal/registry/upstream-registry.schema.json" \
            --arg timestamp "$TIMESTAMP" \
            --argjson servers "$SERVERS" \
            '{
              "$schema": $schema,
              "version": "1.0.0",
              "meta": {
                "last_updated": $timestamp
              },
              "data": {
                "servers": $servers
              }
            }')

          # Write registry.json
          echo "$REGISTRY" | jq '.' > "$REGISTRY_FILE"

          echo "Generated registry with $SERVER_COUNT servers (upstream format)"
          echo "servers_count=$SERVER_COUNT" >> "$GITHUB_OUTPUT"

      - name: Validate Registry Schema
        run: |
          REGISTRY_FILE="${{ env.REGISTRY_PATH }}"

          echo "Validating registry.json against schema constraints..."

          # Download the official schema for reference
          SCHEMA_URL="https://raw.githubusercontent.com/stacklok/toolhive-registry-server/main/internal/registry/upstream-registry.schema.json"
          curl -sfL "$SCHEMA_URL" -o /tmp/registry-schema.json || echo "::warning::Could not download schema - continuing with structural validation only"

          # Validate key constraints that the registry server enforces
          ERRORS=0

          # Check description length (max 100 chars)
          while IFS= read -r desc; do
            LEN=${#desc}
            if [ "$LEN" -gt 100 ]; then
              echo "::error::Description exceeds 100 char limit ($LEN chars): ${desc:0:50}..."
              ERRORS=$((ERRORS + 1))
            fi
          done < <(jq -r '.data.servers[].description // empty' "$REGISTRY_FILE")

          # Check name format (should be owner/repo)
          while IFS= read -r name; do
            if ! echo "$name" | grep -qE '^[^/]+/[^/]+$'; then
              echo "::error::Invalid server name format (expected owner/repo): $name"
              ERRORS=$((ERRORS + 1))
            fi
          done < <(jq -r '.data.servers[].name // empty' "$REGISTRY_FILE")

          # Check required fields
          for i in $(seq 0 $(($(jq '.data.servers | length' "$REGISTRY_FILE") - 1))); do
            NAME=$(jq -r ".data.servers[$i].name" "$REGISTRY_FILE")

            # Check required fields exist
            for field in name title description version; do
              VALUE=$(jq -r ".data.servers[$i].$field // empty" "$REGISTRY_FILE")
              if [ -z "$VALUE" ]; then
                echo "::error::Server '$NAME' missing required field: $field"
                ERRORS=$((ERRORS + 1))
              fi
            done

            # Check remotes array exists and has entries
            REMOTES=$(jq -r ".data.servers[$i].remotes | length" "$REGISTRY_FILE")
            if [ "$REMOTES" -eq 0 ]; then
              echo "::error::Server '$NAME' has no remotes configured"
              ERRORS=$((ERRORS + 1))
            fi
          done

          if [ "$ERRORS" -gt 0 ]; then
            echo "::error::Registry schema validation failed with $ERRORS error(s)"
            exit 1
          fi

          echo "Registry schema validation passed"

      - name: Check for Changes
        id: check-changes
        run: |
          # Compare registry content excluding timestamp to avoid unnecessary commits
          # Upstream format uses meta.last_updated
          CURRENT=$(cat "${{ env.REGISTRY_PATH }}" | jq 'del(.meta.last_updated)' | jq -S '.')
          PREVIOUS=$(git show HEAD:"${{ env.REGISTRY_PATH }}" 2>/dev/null | jq 'del(.meta.last_updated) | del(.last_updated)' | jq -S '.' || echo "{}")

          if [ "$CURRENT" = "$PREVIOUS" ]; then
            echo "No meaningful changes to registry.json (only timestamp differs)"
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
            # Restore original file to avoid committing timestamp-only changes
            git checkout "${{ env.REGISTRY_PATH }}"
          else
            echo "Registry.json has meaningful updates"
            echo "has_changes=true" >> "$GITHUB_OUTPUT"
            git diff "${{ env.REGISTRY_PATH }}"
          fi

      - name: Generate GitHub App Token
        if: steps.check-changes.outputs.has_changes == 'true'
        id: generate-token
        uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2
        with:
          app-id: ${{ secrets.BOT_APP_ID }}
          private-key: ${{ secrets.BOT_APP_PRIVATE_KEY }}

      - name: Commit Catalog Changes
        if: steps.check-changes.outputs.has_changes == 'true'
        env:
          GH_TOKEN: ${{ steps.generate-token.outputs.token }}
        run: |
          # Configure git for GitHub App bot
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Use GitHub App token for push authentication
          git remote set-url origin "https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git"

          git add "${{ env.REGISTRY_PATH }}"
          git commit -m "chore(mcp): auto-generate registry catalog from MCPServer CRDs

          Generated ${{ steps.generate.outputs.servers_count }} catalog entries from MCPServer definitions."
          git push

      - name: Collect Validation Results
        id: collect-results
        run: |
          # Collect validation results from all jobs for PR comment
          # Use the actual image-scan job result to determine per-server status
          MCPSERVER_DIR="${{ env.MCPSERVER_PATH }}"
          IMAGE_SCAN_RESULT="${{ needs.image-scan.result }}"
          VALIDATION_RESULTS=""

          # Get the list of changed files from preflight to mark which were scanned
          CHANGED_FILES='${{ needs.preflight.outputs.mcpserver_files }}'

          for mcpfile in $MCPSERVER_DIR/mcpserver-*.yaml; do
            [ -f "$mcpfile" ] || continue
            NAME=$(yq eval '.metadata.name' "$mcpfile")
            IMAGE=$(yq eval '.spec.image' "$mcpfile")
            MCP_SOURCE=$(grep -oP '#\s*mcp-source:\s*\K.*' "$mcpfile" 2>/dev/null || echo "")

            # Determine scan type
            if [ -n "$MCP_SOURCE" ]; then
              case "$MCP_SOURCE" in
                uvx://*) IMAGE_TYPE="PyPI (pip-audit)" ;;
                npx://*) IMAGE_TYPE="npm (npm audit)" ;;
                go://*)  IMAGE_TYPE="Go (pending)" ;;
                github://*) IMAGE_TYPE="GitHub (pending)" ;;
                *) IMAGE_TYPE="Source (unknown)" ;;
              esac
            else
              case "$IMAGE" in
                uvx://*) IMAGE_TYPE="PyPI (pip-audit)" ;;
                npx://*) IMAGE_TYPE="npm (npm audit)" ;;
                go://*)  IMAGE_TYPE="Go (pending)" ;;
                github://*) IMAGE_TYPE="GitHub (pending)" ;;
                *) IMAGE_TYPE="Docker (Trivy)" ;;
              esac
            fi

            # Check if this file was in the changed set (actually scanned)
            FILE_WAS_SCANNED=false
            if echo "$CHANGED_FILES" | jq -e --arg f "$mcpfile" '.[] | select(. == $f)' >/dev/null 2>&1; then
              FILE_WAS_SCANNED=true
            fi

            # Determine status from actual scan results
            if [ "$IMAGE_TYPE" = "Go (pending)" ] || [ "$IMAGE_TYPE" = "GitHub (pending)" ] || [ "$IMAGE_TYPE" = "Source (unknown)" ]; then
              SCAN_STATUS="⚠️ Manual review"
            elif [ "$FILE_WAS_SCANNED" = "true" ] && [ "$IMAGE_SCAN_RESULT" = "failure" ]; then
              SCAN_STATUS="❌ CVEs found"
            elif [ "$FILE_WAS_SCANNED" = "true" ] && [ "$IMAGE_SCAN_RESULT" = "success" ]; then
              SCAN_STATUS="✅ Passed"
            else
              SCAN_STATUS="⏭️ Not scanned"
            fi
            VALIDATION_RESULTS="${VALIDATION_RESULTS}$(printf '| %s | %s | %s |\n' "$NAME" "$IMAGE_TYPE" "$SCAN_STATUS")"
          done

          {
            echo "validation_results<<EOF"
            printf '%s\n' "$VALIDATION_RESULTS"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"
          echo "scan_result=$IMAGE_SCAN_RESULT" >> "$GITHUB_OUTPUT"

      - name: Generate GitHub App Token (for PR comment)
        if: always() && github.event_name == 'pull_request'
        id: generate-comment-token
        uses: actions/create-github-app-token@67018539274d69449ef7c02e8e71183d1719ab42 # v2
        with:
          app-id: ${{ secrets.BOT_APP_ID }}
          private-key: ${{ secrets.BOT_APP_PRIVATE_KEY }}

      - name: Comment Catalog Report on PR
        if: always() && github.event_name == 'pull_request'
        uses: mshick/add-pr-comment@b8f338c590a895d50bcbfa6c5859251edc8952fc # v2.8.2
        with:
          repo-token: ${{ steps.generate-comment-token.outputs.token }}
          message-id: "mcp-catalog-sync"
          status: ${{ needs.image-scan.result == 'failure' && 'failure' || 'success' }}
          message-success: |
            ## MCP Catalog Report

            Registry catalog updated from MCPServer CRD definitions.

            | Metric | Value |
            |--------|-------|
            | Servers in catalog | ${{ steps.generate.outputs.servers_count }} |
            | Security scan | ✅ Passed |
            | Catalog updated | ${{ steps.check-changes.outputs.has_changes }} |

            ### MCPServer Summary

            | Server | Scan Type | Status |
            |--------|-----------|--------|
            ${{ steps.collect-results.outputs.validation_results }}

            **Safe to merge** - all security checks passed.
          message-failure: |
            ## MCP Catalog Report

            Registry catalog updated from MCPServer CRD definitions.

            | Metric | Value |
            |--------|-------|
            | Servers in catalog | ${{ steps.generate.outputs.servers_count }} |
            | Security scan | ❌ HIGH/CRITICAL CVEs detected |
            | Catalog updated | ${{ steps.check-changes.outputs.has_changes }} |

            ### MCPServer Summary

            | Server | Scan Type | Status |
            |--------|-----------|--------|
            ${{ steps.collect-results.outputs.validation_results }}

            **Blocked from merge** - see security scan comment above for CVE details.

  # =============================================================================
  # Job 6: Status Check (BLOCKING on security failures)
  # =============================================================================
  mcp-catalog-status:
    name: MCP Catalog Sync Status
    needs: [preflight, validate, classify, image-scan, build-container, mcp-validate, generate-catalog]
    if: always()
    runs-on: gha-runner-scale-set
    steps:
      - name: Check Results
        run: |
          echo "=== Job Results ==="
          echo "Preflight: ${{ needs.preflight.result }}"
          echo "Validate: ${{ needs.validate.result }}"
          echo "Classify: ${{ needs.classify.result }}"
          echo "Image Scan: ${{ needs.image-scan.result }}"
          echo "Build Container: ${{ needs.build-container.result }}"
          echo "MCP Validate: ${{ needs.mcp-validate.result }}"
          echo "Generate Catalog: ${{ needs.generate-catalog.result }}"
          echo ""

          ERRORS=0
          WARNINGS=0

          # Helper: check if a job result is a failure (not success and not skipped)
          # GitHub Actions result values: success, failure, cancelled, skipped
          # When a job fails at "Set up job" (infra/SSL), result may be 'failure' or empty
          check_required() {
            local job_name="$1"
            local result="$2"
            if [ "$result" != "success" ] && [ "$result" != "skipped" ]; then
              echo "::error::${job_name} failed (result: ${result:-empty})"
              return 1
            fi
            return 0
          }

          # Risk acceptance: allow merging despite security scan failures
          # Apply the 'security-risk-accepted' label to the PR to override
          RISK_ACCEPTED="false"
          if [ "${{ github.event_name }}" = "push" ]; then
            # Post-merge: security gate is informational only (code already merged)
            RISK_ACCEPTED="true"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            PR_LABELS="${{ join(github.event.pull_request.labels.*.name, ',') }}"
            if echo "$PR_LABELS" | grep -q "security-risk-accepted"; then
              RISK_ACCEPTED="true"
              echo "::warning::Security risk accepted via PR label on PR #${{ github.event.pull_request.number }}"
            fi
          fi

          # Store results in variables for reliable checking
          PREFLIGHT_RESULT="${{ needs.preflight.result }}"
          VALIDATE_RESULT="${{ needs.validate.result }}"
          CLASSIFY_RESULT="${{ needs.classify.result }}"
          IMAGE_SCAN_RESULT="${{ needs.image-scan.result }}"
          BUILD_RESULT="${{ needs.build-container.result }}"
          MCP_VALIDATE_RESULT="${{ needs.mcp-validate.result }}"
          GENERATE_RESULT="${{ needs.generate-catalog.result }}"

          # Preflight must succeed for the pipeline to work at all
          if ! check_required "Preflight" "$PREFLIGHT_RESULT"; then
            echo "  Cannot determine MCPServer changes"
            ERRORS=$((ERRORS + 1))
          fi

          # Only require downstream jobs to pass if MCPServers changed
          if [ "${{ needs.preflight.outputs.mcpservers_changed }}" = "true" ]; then
            # Validate is required only when there are files to validate (not just deletions)
            # When validate is skipped (due to empty matrix from deletions), that's OK
            if ! check_required "Validate" "$VALIDATE_RESULT"; then
              echo "  MCPServer validation failed - check for security issues"
              ERRORS=$((ERRORS + 1))
            fi

            # Classify must succeed for the pipeline to work
            if ! check_required "Classify" "$CLASSIFY_RESULT"; then
              ERRORS=$((ERRORS + 1))
            fi

            # Security scan - BLOCKING unless risk is explicitly accepted
            if ! check_required "Security Scan" "$IMAGE_SCAN_RESULT"; then
              if [ "$RISK_ACCEPTED" = "true" ]; then
                echo "::warning::Security Scan failed but risk accepted — treating as warning"
                WARNINGS=$((WARNINGS + 1))
              else
                echo ""
                echo "Options to resolve:"
                echo "  1. Wait for the upstream maintainer to release a patched image"
                echo "  2. Open an issue on the upstream repository"
                echo "  3. Pin to an older version without known CVEs"
                echo "  4. Apply the 'security-risk-accepted' label to accept the risk and merge anyway"
                ERRORS=$((ERRORS + 1))
              fi
            fi

            # Build-container: skipped is OK (no source-built containers)
            # When risk is accepted and scan failed, build may also fail/skip — that's expected
            if ! check_required "Build Container" "$BUILD_RESULT"; then
              if [ "$RISK_ACCEPTED" = "true" ] && [ "$IMAGE_SCAN_RESULT" != "success" ]; then
                echo "::warning::Build Container skipped/failed due to accepted scan failure"
                WARNINGS=$((WARNINGS + 1))
              else
                echo ""
                echo "  1. Review the build-container job logs above"
                echo "  2. Check the mcp-source specification is valid"
                echo "  3. Ensure the package exists and version is correct"
                ERRORS=$((ERRORS + 1))
              fi
            fi

            # Generate-catalog is required when MCPServers change (additions or deletions)
            if ! check_required "Generate Catalog" "$GENERATE_RESULT"; then
              ERRORS=$((ERRORS + 1))
            fi
          fi

          # Report on optional jobs (non-blocking warnings)
          if [ "$MCP_VALIDATE_RESULT" = "failure" ]; then
            echo "::warning::MCP protocol validation failed - server may need external dependencies"
            echo "This is a warning only - the server may still work correctly in production"
            WARNINGS=$((WARNINGS + 1))
          fi

          # Final result
          if [ "$ERRORS" -gt 0 ]; then
            echo ""
            echo "========================================"
            echo "  MCP CATALOG SYNC FAILED ($ERRORS error(s), $WARNINGS warning(s))"
            echo "========================================"
            echo ""
            echo "Review the errors above and check PR comments from homebot-0 for details."
            exit 1
          fi

          echo ""
          echo "========================================"
          echo "  MCP CATALOG SYNC PASSED ($WARNINGS warning(s))"
          echo "========================================"
          echo ""
          echo "All required checks passed. This PR is safe to merge."
