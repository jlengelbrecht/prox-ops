---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
  namespace: ai
spec:
  chart:
    spec:
      chart: litellm-helm
      # renovate: datasource=helm registryUrl=oci://ghcr.io/berriai
      version: 0.1.830
      sourceRef:
        kind: HelmRepository
        name: litellm
        namespace: ai
  interval: 1h
  # Depend on PostgreSQL to be ready before LiteLLM
  dependsOn:
    - name: litellm-postgres
      namespace: ai
  values:
    # Image configuration - uses litellm-database (debian-based) for Prisma compatibility
    image:
      repository: ghcr.io/berriai/litellm-database
      pullPolicy: Always
      # renovate: datasource=docker depName=ghcr.io/berriai/litellm-database
      tag: main-v1.80.9-nightly

    # Replica count
    replicaCount: 1

    # Master key from ExternalSecret
    masterkeySecretName: litellm-masterkey
    masterkeySecretKey: masterkey

    # Database configuration - use existing PostgreSQL
    db:
      useExisting: true
      deployStandalone: false
      endpoint: litellm-postgres.ai.svc.cluster.local
      database: litellm
      secret:
        name: litellm-db-credentials
        usernameKey: username
        passwordKey: password

    # Use existing ConfigMap for proxy configuration
    proxyConfigMap:
      create: false
      name: litellm-config
      key: config.yaml

    # Pod annotations
    podAnnotations:
      security.homelab/network: "Internal + external API via envoy-internal"
      security.homelab/purpose: "OpenAI-compatible API gateway for Ollama"

    # Pod security context - defense in depth
    podSecurityContext:
      runAsUser: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      fsGroup: 65534
      fsGroupChangePolicy: OnRootMismatch
      seccompProfile:
        type: RuntimeDefault

    # Container security context
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false  # Prisma requires write access
      capabilities:
        drop:
          - ALL

    # Resource limits
    resources:
      requests:
        cpu: 200m
        memory: 256Mi
      limits:
        cpu: 1
        memory: 1Gi

    # Service configuration
    service:
      type: ClusterIP
      port: 4000

    # Separate health app for more reliable probes
    separateHealthApp: true
    separateHealthPort: 8081

    # Migration job settings
    migrationJob:
      enabled: true
      retries: 3
      backoffLimit: 4
      disableSchemaUpdate: false
      ttlSecondsAfterFinished: 120
      hooks:
        # Enable Helm hooks for migration job orchestration during install/upgrade
        argocd:
          enabled: false
        helm:
          enabled: true

    # Disable internal PostgreSQL (we use our own)
    postgresql:
      enabled: false

    # Disable Redis (not needed for single-node)
    redis:
      enabled: false

    # Environment variables
    envVars:
      LITELLM_TELEMETRY: "false"
      LITELLM_LOG: "INFO"
