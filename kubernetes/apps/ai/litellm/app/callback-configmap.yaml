---
# STORY-063: Custom callback to inject Anthropic OAuth token for Claude Max subscription
# Workaround for LiteLLM issue #19618 - OAuth tokens not properly forwarded
apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-oauth-callback
  namespace: ai
data:
  anthropic_oauth_callback.py: |
    """
    Custom LiteLLM callback to inject Anthropic OAuth token into requests.

    This callback works around LiteLLM issue #19618 where OAuth tokens
    are not properly forwarded to Anthropic. It injects the OAuth token
    as an Authorization: Bearer header via extra_headers for Claude models.

    Reference: https://github.com/BerriAI/litellm/issues/19618
    """
    import os
    from typing import Literal, Optional, Union
    from litellm.integrations.custom_logger import CustomLogger
    from litellm.proxy._types import UserAPIKeyAuth
    from litellm.caching.caching import DualCache


    class AnthropicOAuthCallback(CustomLogger):
        """Injects Anthropic OAuth token for Claude Max subscription requests."""

        def __init__(self):
            super().__init__()
            self.oauth_token = os.environ.get("ANTHROPIC_OAUTH_TOKEN", "")
            if not self.oauth_token:
                print("WARNING: ANTHROPIC_OAUTH_TOKEN not set - OAuth injection disabled")
            else:
                print(f"AnthropicOAuthCallback initialized with token: {self.oauth_token[:20]}...")

        def _is_anthropic_model(self, model: str) -> bool:
            """Check if the model is an Anthropic/Claude model."""
            if not model:
                return False
            model_lower = model.lower()
            return any(x in model_lower for x in ["anthropic", "claude"])

        async def async_pre_call_hook(
            self,
            user_api_key_dict: UserAPIKeyAuth,
            cache: DualCache,
            data: dict,
            call_type: Literal[
                "completion",
                "text_completion",
                "embeddings",
                "image_generation",
                "moderation",
                "audio_transcription",
                "pass_through_endpoint",
                "rerank"
            ],
        ) -> Optional[Union[Exception, str, dict]]:
            """
            Inject OAuth token for Anthropic models.
            Sets api_key to OAuth token so LiteLLM sends it as x-api-key.
            Also adds Authorization: Bearer header as fallback.
            """
            print(f"AnthropicOAuthCallback: async_pre_call_hook called, model={data.get('model', 'unknown')}")

            if not self.oauth_token:
                print("AnthropicOAuthCallback: No OAuth token, skipping")
                return data

            model = data.get("model", "")

            # Only inject for Anthropic/Claude models
            if not self._is_anthropic_model(model):
                print(f"AnthropicOAuthCallback: Not Anthropic model, skipping: {model}")
                return data

            # Set api_key to OAuth token - LiteLLM will send this as x-api-key
            # Anthropic accepts OAuth tokens via x-api-key header as well
            data["api_key"] = self.oauth_token

            # Also add Authorization: Bearer header as backup
            if "extra_headers" not in data:
                data["extra_headers"] = {}
            data["extra_headers"]["Authorization"] = f"Bearer {self.oauth_token}"

            print(f"AnthropicOAuthCallback: Injected OAuth token for model {model}")
            print(f"AnthropicOAuthCallback: api_key set, extra_headers={list(data.get('extra_headers', {}).keys())}")
            return data


    # Export the callback instance
    anthropic_oauth_callback = AnthropicOAuthCallback()
