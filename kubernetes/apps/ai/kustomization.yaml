---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: ai

resources:
  - ./namespace.yaml
  # EPIC-022: Local AI Platform
  # Architecture validated: 2025-12-10
  # See: .claude/.ai-docs/epics/EPIC-022-local-ai-platform.md
  #
  # Phase 1: Core Platform
  - ./open-webui/storage/ks.yaml  # Storage with prune: false - MUST come before open-webui
  - ./open-webui/ks.yaml          # STORY-081: Chat UI
  #
  # Phase 2: API Layer
  - ./litellm-postgres/storage/ks.yaml  # PostgreSQL storage with prune: false
  - ./litellm-postgres/ks.yaml          # PostgreSQL for LiteLLM virtual keys
  - ./litellm/storage/ks.yaml  # Storage with prune: false - MUST come before litellm
  - ./litellm/ks.yaml          # STORY-075: OpenAI-compatible API gateway
  #
  # Phase 3: Web Search & Crawling (STORY-085)
  - ./searxng/ks.yaml           # SearXNG meta-search engine
  - ./firecrawl/ks.yaml         # Firecrawl web crawler (depends on SearXNG)
  #
  # Phase 4: ToolHive MCP Platform (EPIC-029)
  # Note: toolhive-registry moved to mcp namespace for MCPServer discovery
  - ./toolhive-ui/ks.yaml         # STORY-029-3: Cloud UI (MCP management)
  #
  # Phase 5: KServe ML Inference Platform (EPIC-028)
  # Scalable serverless AI inference with Knative + vLLM
  # See: .claude/.ai-docs/epics/EPIC-028-scalable-ai-inference-platform.md
  - ./model-cache/ks.yaml         # STORY-137: Shared model cache (500Gi CephFS RWX)
  - ./kserve/ks.yaml              # STORY-136: KServe controller + CRDs
