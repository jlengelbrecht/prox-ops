---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: observability
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 68.2.2
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: observability
  interval: 1h
  timeout: 15m
  install:
    remediation:
      retries: 3
    crds: CreateReplace
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
    crds: CreateReplace
  values:
    # Prometheus configuration
    prometheus:
      enabled: true
      prometheusSpec:
        # Data retention
        retention: 30d
        retentionSize: "90GB"

        # Resource limits
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi

        # Storage configuration
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: ceph-block
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 100Gi

        # Service monitors
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false

        # Additional alert rules from ConfigMaps
        additionalPrometheusRulesSelector:
          matchLabels:
            prometheus: kube-prometheus-stack
            role: alert-rules

        # Enable remote write receiver (for future use)
        enableRemoteWriteReceiver: false

        # Enable feature flags
        enableFeatures: []

        # Scrape configs
        additionalScrapeConfigs: []

        # Pod configuration
        podMetadata:
          labels:
            app: prometheus

        # Replicas (for homelab, single replica is sufficient)
        replicas: 1

        # WAL compression
        walCompression: true

    # Grafana configuration
    grafana:
      enabled: true

      # Disable default datasource provisioning from chart
      forceDeployDatasources: false

      # Admin credentials from secret
      admin:
        existingSecret: grafana-admin
        userKey: admin-user
        passwordKey: admin-password

      # Persistence
      persistence:
        enabled: true
        type: pvc
        storageClassName: ceph-block
        accessModes:
          - ReadWriteOnce
        size: 10Gi

      # Service configuration for LoadBalancer
      service:
        type: LoadBalancer
        port: 80
        targetPort: 3000
        annotations:
          io.cilium/lb-ipam-ips: "10.20.67.24"

      # Ingress disabled (using LoadBalancer)
      ingress:
        enabled: false

      # Resource limits
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi

      # Deployment strategy - use Recreate for RWO volumes
      deploymentStrategy:
        type: Recreate

      # Grafana configuration
      grafana.ini:
        server:
          domain: grafana.homelab0.org
          root_url: "http://grafana.homelab0.org"
        analytics:
          check_for_updates: false
          reporting_enabled: false
        log:
          mode: console
        paths:
          data: /var/lib/grafana/
          logs: /var/log/grafana
          plugins: /var/lib/grafana/plugins
          provisioning: /etc/grafana/provisioning

      # Default dashboards
      defaultDashboardsEnabled: true
      defaultDashboardsTimezone: UTC

      # Datasources - manually provision since we disabled chart defaults
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              url: http://kube-prometheus-stack-prometheus.observability.svc.cluster.local:9090
              access: proxy
              isDefault: true
              jsonData:
                timeInterval: 30s
            - name: Loki
              type: loki
              url: http://loki:3100
              access: proxy
              isDefault: false
              jsonData:
                maxLines: 1000
                derivedFields:
                  - datasourceUid: Prometheus
                    matcherRegex: "traceID=(\\w+)"
                    name: TraceID
                    url: "$${__value.raw}"

      # Dashboard providers
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: 'default'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/default

      # Sidecar for dashboard discovery
      sidecar:
        dashboards:
          enabled: true
          defaultFolderName: "General"
          label: grafana_dashboard
          labelValue: "1"
          folderAnnotation: grafana_folder
          searchNamespace: ALL
          provider:
            foldersFromFilesStructure: true
        datasources:
          enabled: false

    # AlertManager configuration
    alertmanager:
      enabled: true
      alertmanagerSpec:
        # Resource limits
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi

        # Storage configuration
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: ceph-block
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 5Gi

        # Replicas
        replicas: 1

        # Retention
        retention: 168h  # 7 days

        # Pod configuration
        podMetadata:
          labels:
            app: alertmanager

      # AlertManager routing configuration
      config:
        global:
          resolve_timeout: 5m

        # Inhibition rules - prevent alert spam
        inhibit_rules:
          - source_matchers:
              - severity = "critical"
            target_matchers:
              - severity = "warning"
            equal:
              - namespace
              - alertname
          - source_matchers:
              - severity =~ "warning|critical"
            target_matchers:
              - severity = "info"
            equal:
              - namespace
              - alertname
          - source_matchers:
              - alertname = "NodeDown"
            target_matchers:
              - alertname =~ "Node.*"
            equal:
              - node

        # Routing tree
        route:
          receiver: 'default'
          group_by:
            - alertname
            - namespace
            - severity
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 4h

          routes:
            # Critical alerts - immediate notification
            - matchers:
                - severity = "critical"
              receiver: 'critical-alerts'
              group_wait: 10s
              group_interval: 2m
              repeat_interval: 1h
              continue: false

            # High severity alerts
            - matchers:
                - severity = "high"
              receiver: 'high-alerts'
              group_wait: 30s
              group_interval: 5m
              repeat_interval: 2h
              continue: false

            # Security alerts (Tetragon)
            - matchers:
                - alertname =~ ".*Tetragon.*|.*Security.*"
              receiver: 'security-alerts'
              group_wait: 30s
              group_interval: 5m
              repeat_interval: 2h
              continue: false

            # GPU alerts
            - matchers:
                - alertname =~ ".*GPU.*"
              receiver: 'general-alerts'
              group_wait: 1m
              group_interval: 10m
              repeat_interval: 4h
              continue: false

            # Storage alerts (Ceph)
            - matchers:
                - alertname =~ ".*Ceph.*|.*Storage.*"
              receiver: 'general-alerts'
              group_wait: 1m
              group_interval: 10m
              repeat_interval: 4h
              continue: false

            # DMZ namespace (Plex)
            - matchers:
                - namespace = "media"
              receiver: 'general-alerts'
              group_wait: 1m
              group_interval: 10m
              repeat_interval: 4h
              continue: false

            # IoT namespace (Home Assistant)
            - matchers:
                - namespace = "iot"
              receiver: 'general-alerts'
              group_wait: 1m
              group_interval: 10m
              repeat_interval: 4h
              continue: false

            # Warning alerts
            - matchers:
                - severity = "warning"
              receiver: 'general-alerts'
              group_wait: 2m
              group_interval: 15m
              repeat_interval: 6h
              continue: false

            # Info alerts (low priority)
            - matchers:
                - severity = "info"
              receiver: 'info-alerts'
              group_wait: 5m
              group_interval: 30m
              repeat_interval: 12h
              continue: false

            # Watchdog alert (required)
            - matchers:
                - alertname = "Watchdog"
              receiver: 'null'

        # Receivers configuration with alertmanager-discord webhook adapter
        # All receivers point to the internal service which handles Discord formatting
        receivers:
          - name: 'null'
            # No notifications for null receiver

          - name: 'default'
            # No notifications for default receiver

          - name: 'critical-alerts'
            webhook_configs:
              - url: 'http://alertmanager-discord.observability.svc.cluster.local:9094/webhook'
                send_resolved: true
                http_config:
                  follow_redirects: true
                max_alerts: 10

          - name: 'security-alerts'
            webhook_configs:
              - url: 'http://alertmanager-discord.observability.svc.cluster.local:9094/webhook'
                send_resolved: true
                http_config:
                  follow_redirects: true
                max_alerts: 10

          - name: 'general-alerts'
            webhook_configs:
              - url: 'http://alertmanager-discord.observability.svc.cluster.local:9094/webhook'
                send_resolved: true
                http_config:
                  follow_redirects: true
                max_alerts: 10

          - name: 'high-alerts'
            webhook_configs:
              - url: 'http://alertmanager-discord.observability.svc.cluster.local:9094/webhook'
                send_resolved: true
                max_alerts: 10

          - name: 'info-alerts'
            webhook_configs:
              - url: 'http://alertmanager-discord.observability.svc.cluster.local:9094/webhook'
                send_resolved: false
                max_alerts: 10

        templates: []

    # Prometheus Operator configuration
    prometheusOperator:
      enabled: true

      # Resource limits
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi

      # Prometheus config reloader
      prometheusConfigReloader:
        resources:
          requests:
            cpu: 10m
            memory: 32Mi
          limits:
            cpu: 200m
            memory: 64Mi

    # Kube State Metrics
    kubeStateMetrics:
      enabled: true

    # Node Exporter
    nodeExporter:
      enabled: true

      # Resource limits
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 200m
          memory: 128Mi

    # Default rules
    defaultRules:
      create: true
      rules:
        alertmanager: true
        etcd: true
        configReloaders: true
        general: true
        k8s: true
        kubeApiserverAvailability: true
        kubeApiserverSlos: true
        kubeControllerManager: true
        kubelet: true
        kubeProxy: true
        kubePrometheusGeneral: true
        kubePrometheusNodeRecording: true
        kubernetesApps: true
        kubernetesResources: true
        kubernetesStorage: true
        kubernetesSystem: true
        kubeSchedulerAlerting: true
        kubeSchedulerRecording: true
        kubeStateMetrics: true
        network: true
        node: true
        nodeExporterAlerting: true
        nodeExporterRecording: true
        prometheus: true
        prometheusOperator: true

    # Global configuration
    global:
      rbac:
        create: true
        createAggregateClusterRoles: true
